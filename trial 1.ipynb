{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame              activity  confidence\n",
      "0      0  opening_door_outside       53.74\n",
      "1      1  opening_door_outside       54.08\n",
      "2      2  opening_door_outside       57.44\n",
      "3      3  opening_door_outside       57.44\n",
      "4      4  opening_door_outside       57.44\n"
     ]
    }
   ],
   "source": [
    "# Load ground truth\n",
    "ground_truth = pd.read_csv('./test_data/midlevel.chunks_90.split_0.train.csv')\n",
    "\n",
    "# Parse the predictions.log file\n",
    "predictions = []\n",
    "with open('predictions.log', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Split the line to extract frame and activity information\n",
    "            parts = line.strip().split(' - ')  # Splitting by \" - \" to separate timestamp and frame info\n",
    "            frame_part = parts[1].split(': ')[0]  # Extract \"Frame X\"\n",
    "            frame = int(frame_part.split()[1])  # Extract the frame number after \"Frame\"\n",
    "\n",
    "            # Extract activity and confidence\n",
    "            activity_part = parts[1].split(': ', maxsplit=1)[1]  # This contains \"Predicted Activity: XYZ, Confidence: XX.XX%\"\n",
    "            activity = activity_part.split(', Confidence')[0].replace(\"Predicted Activity: \", \"\").strip()  # Extract actual activity\n",
    "            \n",
    "            # Extract confidence if it exists\n",
    "            confidence = 0.0  # Default confidence\n",
    "            if \"Confidence\" in activity_part:  # Check if \"Confidence\" exists in the string\n",
    "                confidence = float(activity_part.split('Confidence: ')[1].strip('%'))  # Extract confidence as float\n",
    "\n",
    "            # Append to predictions list\n",
    "            predictions.append({'frame': frame, 'activity': activity, 'confidence': confidence})\n",
    "        \n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(f\"Skipping line due to error: {line.strip()} -> {e}\")\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Display the predictions DataFrame\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     frame_start  frame_end               activity\n",
      "0              0         54   opening_door_outside\n",
      "1             55         90   closing_door_outside\n",
      "2             91        136   opening_door_outside\n",
      "3            137        157           entering_car\n",
      "4            158        184    closing_door_inside\n",
      "..           ...        ...                    ...\n",
      "323        18886      18904    fastening_seat_belt\n",
      "324        18905      18945  unfastening_seat_belt\n",
      "325        18946      18978    opening_door_inside\n",
      "326        18979      19012            exiting_car\n",
      "327        19013      19070   closing_door_outside\n",
      "\n",
      "[328 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_predictions_to_segments(predictions):\n",
    "    segments = []\n",
    "    current_activity = None\n",
    "    current_start = None\n",
    "\n",
    "    for idx, row in predictions.iterrows():\n",
    "        frame = row['frame']\n",
    "        activity = row['activity']\n",
    "\n",
    "        # Start a new segment if the activity changes\n",
    "        if activity != current_activity:\n",
    "            if current_activity is not None:\n",
    "                # Save the previous segment\n",
    "                segments.append({\n",
    "                    'frame_start': current_start,\n",
    "                    'frame_end': frame - 1,\n",
    "                    'activity': current_activity\n",
    "                })\n",
    "            # Start a new segment\n",
    "            current_activity = activity\n",
    "            current_start = frame\n",
    "\n",
    "    # Save the last segment\n",
    "    if current_activity is not None:\n",
    "        segments.append({\n",
    "            'frame_start': current_start,\n",
    "            'frame_end': predictions.iloc[-1]['frame'],\n",
    "            'activity': current_activity\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(segments)\n",
    "\n",
    "# Example: Convert frame-level predictions into segments\n",
    "segments_df = convert_predictions_to_segments(predictions_df)\n",
    "\n",
    "# Display the segments\n",
    "print(segments_df)\n",
    "segments_df.to_csv('segmented_activities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['closing_door_outside', 'opening_door_outside', 'entering_car', 'closing_door_inside', 'fastening_seat_belt', 'using_multimedia_display', 'sitting_still', 'pressing_automation_button', 'fetching_an_object', 'opening_laptop', 'working_on_laptop', 'interacting_with_phone', 'closing_laptop', 'placing_an_object', 'unfastening_seat_belt', 'putting_on_jacket', 'opening_bottle', 'drinking', 'closing_bottle', 'looking_or_moving_around (e.g. searching)', 'preparing_food', 'eating', 'taking_off_sunglasses', 'putting_on_sunglasses', 'reading_newspaper', 'writing', 'talking_on_phone', 'reading_magazine', 'taking_off_jacket', 'opening_door_inside', 'exiting_car', 'opening_backpack', 'putting_laptop_into_backpack', 'taking_laptop_from_backpack']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "file_path = './test_data/midlevel.chunks_90.split_0.train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the unique activities from the 'activity' column\n",
    "unique_activities = data['activity'].dropna().unique()\n",
    "\n",
    "# Convert to a list\n",
    "unique_activities_list = list(unique_activities)\n",
    "\n",
    "# Print the unique activities\n",
    "print(unique_activities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class (%): {'closing_door_outside': '50.00%', 'opening_door_outside': '100.00%', 'entering_car': '100.00%', 'closing_door_inside': '50.00%', 'fastening_seat_belt': '50.00%', 'using_multimedia_display': '69.57%', 'sitting_still': '66.04%', 'pressing_automation_button': '52.63%', 'fetching_an_object': '75.00%', 'opening_laptop': '66.67%', 'working_on_laptop': '75.00%', 'interacting_with_phone': '62.50%', 'closing_laptop': '20.00%', 'placing_an_object': '41.25%', 'unfastening_seat_belt': '50.00%', 'putting_on_jacket': '26.67%', 'opening_bottle': '83.33%', 'drinking': '75.00%', 'closing_bottle': '80.00%', 'looking_or_moving_around (e.g. searching)': '27.27%', 'preparing_food': '26.67%', 'eating': '88.89%', 'taking_off_sunglasses': '33.33%', 'putting_on_sunglasses': '100.00%', 'reading_newspaper': '66.67%', 'writing': '50.00%', 'talking_on_phone': '100.00%', 'reading_magazine': '100.00%', 'taking_off_jacket': '100.00%', 'opening_door_inside': '33.33%', 'exiting_car': '100.00%', 'opening_backpack': '0.00%', 'putting_laptop_into_backpack': '0.00%', 'taking_laptop_from_backpack': '0.00%'}\n",
      "Recall per class (%): {'closing_door_outside': '11.11%', 'opening_door_outside': '66.67%', 'entering_car': '9.09%', 'closing_door_inside': '6.67%', 'fastening_seat_belt': '5.48%', 'using_multimedia_display': '14.95%', 'sitting_still': '2.28%', 'pressing_automation_button': '17.54%', 'fetching_an_object': '5.00%', 'opening_laptop': '13.33%', 'working_on_laptop': '1.12%', 'interacting_with_phone': '1.84%', 'closing_laptop': '7.69%', 'placing_an_object': '15.79%', 'unfastening_seat_belt': '9.68%', 'putting_on_jacket': '4.00%', 'opening_bottle': '13.89%', 'drinking': '7.59%', 'closing_bottle': '11.11%', 'looking_or_moving_around (e.g. searching)': '5.88%', 'preparing_food': '14.81%', 'eating': '1.94%', 'taking_off_sunglasses': '13.04%', 'putting_on_sunglasses': '10.71%', 'reading_newspaper': '0.69%', 'writing': '1.32%', 'talking_on_phone': '1.09%', 'reading_magazine': '0.51%', 'taking_off_jacket': '5.71%', 'opening_door_inside': '7.69%', 'exiting_car': '6.67%', 'opening_backpack': '0.00%', 'putting_laptop_into_backpack': '0.00%', 'taking_laptop_from_backpack': '0.00%'}\n",
      "Overall Precision: 54.30%\n",
      "Overall Recall: 3.81%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multiclass(ground_truth, predictions, activity_classes):\n",
    "    # Initialize metrics for each activity\n",
    "    metrics = {cls: {'tp': 0, 'fp': 0, 'fn': 0} for cls in activity_classes}\n",
    "    matched_chunks = set()  # Tracks matched ground truth chunks (annotation_id, chunk_id)\n",
    "\n",
    "    # Iterate over predicted segments\n",
    "    for _, pred in predictions.iterrows():\n",
    "        pred_start = pred['frame_start']\n",
    "        pred_end = pred['frame_end']\n",
    "        pred_activity = pred['activity']\n",
    "\n",
    "        # Calculate the midpoint of the prediction\n",
    "        pred_midpoint = (pred_start + pred_end) / 2\n",
    "\n",
    "        match_found = False\n",
    "        for _, gt in ground_truth.iterrows():\n",
    "            chunk_key = (gt['annotation_id'], gt['chunk_id'])  # Unique identifier for ground truth chunks\n",
    "\n",
    "            # Check if the prediction matches this ground truth chunk\n",
    "            if gt['activity'] == pred_activity and gt['frame_start'] <= pred_midpoint <= gt['frame_end']:\n",
    "                if chunk_key not in matched_chunks:\n",
    "                    metrics[pred_activity]['tp'] += 1  # True Positive\n",
    "                    matched_chunks.add(chunk_key)  # Mark this chunk as matched\n",
    "                    match_found = True\n",
    "                    break\n",
    "                else:\n",
    "                    metrics[pred_activity]['fp'] += 1  # False Positive for duplicate detection\n",
    "                    match_found = True\n",
    "\n",
    "        if not match_found:\n",
    "            if pred_activity in metrics:\n",
    "                metrics[pred_activity]['fp'] += 1  # False Positive for unmatched prediction\n",
    "\n",
    "    # Count False Negatives (ground truth chunks without a match)\n",
    "    for _, gt in ground_truth.iterrows():\n",
    "        chunk_key = (gt['annotation_id'], gt['chunk_id'])\n",
    "        if chunk_key not in matched_chunks:\n",
    "            metrics[gt['activity']]['fn'] += 1\n",
    "\n",
    "    # Calculate Precision, Recall for each activity class\n",
    "    precision, recall = {}, {}\n",
    "    for cls in activity_classes:\n",
    "        tp = metrics[cls]['tp']\n",
    "        fp = metrics[cls]['fp']\n",
    "        fn = metrics[cls]['fn']\n",
    "\n",
    "        precision[cls] = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0  # Convert to percentage\n",
    "        recall[cls] = tp / (tp + fn) * 100 if (tp + fn) > 0 else 0  # Convert to percentage\n",
    "\n",
    "    # Calculate overall Precision and Recall\n",
    "    overall_tp = sum(metrics[cls]['tp'] for cls in activity_classes)\n",
    "    overall_fp = sum(metrics[cls]['fp'] for cls in activity_classes)\n",
    "    overall_fn = sum(metrics[cls]['fn'] for cls in activity_classes)\n",
    "\n",
    "    overall_precision = overall_tp / (overall_tp + overall_fp) * 100 if (overall_tp + overall_fp) > 0 else 0\n",
    "    overall_recall = overall_tp / (overall_tp + overall_fn) * 100 if (overall_tp + overall_fn) > 0 else 0\n",
    "\n",
    "    return precision, recall, overall_precision, overall_recall\n",
    "\n",
    "# Example usage:\n",
    "activity_classes = unique_activities_list\n",
    "precision, recall, overall_precision, overall_recall = evaluate_multiclass(ground_truth, segments_df, activity_classes)\n",
    "\n",
    "print(\"Precision per class (%):\", {cls: f\"{precision[cls]:.2f}%\" for cls in precision})\n",
    "print(\"Recall per class (%):\", {cls: f\"{recall[cls]:.2f}%\" for cls in recall})\n",
    "print(f\"Overall Precision: {overall_precision:.2f}%\")\n",
    "print(f\"Overall Recall: {overall_recall:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
