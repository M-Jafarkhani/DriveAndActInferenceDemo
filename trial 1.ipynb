{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the ground truth dataset: 6642\n",
      "Number of rows in the ground truth dataset having video run1b_2018-05-29-14-02-47.kinect_color : 363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>activity</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "      <td>closing_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>130</td>\n",
       "      <td>opening_door_outside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>156</td>\n",
       "      <td>entering_car</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "      <td>174</td>\n",
       "      <td>closing_door_inside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>219</td>\n",
       "      <td>fastening_seat_belt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>6</td>\n",
       "      <td>219</td>\n",
       "      <td>230</td>\n",
       "      <td>fastening_seat_belt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>265</td>\n",
       "      <td>using_multimedia_display</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>8</td>\n",
       "      <td>2985</td>\n",
       "      <td>3010</td>\n",
       "      <td>sitting_still</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>9</td>\n",
       "      <td>3010</td>\n",
       "      <td>3055</td>\n",
       "      <td>pressing_automation_button</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>vp1/run1b_2018-05-29-14-02-47.kinect_color</td>\n",
       "      <td>10</td>\n",
       "      <td>3055</td>\n",
       "      <td>3101</td>\n",
       "      <td>sitting_still</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id                                     file_id  annotation_id  \\\n",
       "0               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              1   \n",
       "1               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              3   \n",
       "2               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              4   \n",
       "3               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              5   \n",
       "4               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              6   \n",
       "5               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              6   \n",
       "6               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              7   \n",
       "7               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              8   \n",
       "8               1  vp1/run1b_2018-05-29-14-02-47.kinect_color              9   \n",
       "9               1  vp1/run1b_2018-05-29-14-02-47.kinect_color             10   \n",
       "\n",
       "   frame_start  frame_end                    activity  chunk_id  \n",
       "0           58         82        closing_door_outside         0  \n",
       "1          102        130        opening_door_outside         0  \n",
       "2          130        156                entering_car         0  \n",
       "3          156        174         closing_door_inside         0  \n",
       "4          174        219         fastening_seat_belt         0  \n",
       "5          219        230         fastening_seat_belt         1  \n",
       "6          230        265    using_multimedia_display         0  \n",
       "7         2985       3010               sitting_still         0  \n",
       "8         3010       3055  pressing_automation_button         0  \n",
       "9         3055       3101               sitting_still         0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ground truth\n",
    "ground_truth = pd.read_csv('./test_data/midlevel.chunks_90.split_0.train.csv')\n",
    "num_rows = ground_truth.shape[0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of rows in the ground truth dataset: {num_rows}\")\n",
    "# Filter the dataset for the specific file_id\n",
    "filtered_df = ground_truth[ground_truth['file_id'] == \"vp1/run1b_2018-05-29-14-02-47.kinect_color\"]\n",
    "\n",
    "num_rows2 = filtered_df.shape[0]\n",
    "print(f\"Number of rows in the ground truth dataset having video run1b_2018-05-29-14-02-47.kinect_color : {num_rows2}\")\n",
    "\n",
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Group by annotation_id and merge frame ranges for the same activity\n",
    "segmentedGroundTruth_df = filtered_df.groupby([\"annotation_id\", \"activity\"]).agg({\n",
    "    \"frame_start\": \"min\",  # Get the earliest frame in the chunk\n",
    "    \"frame_end\": \"max\",    # Get the latest frame in the chunk\n",
    "    \"chunk_id\": lambda x: \", \".join(map(str, sorted(x)))  # Combine chunk_ids\n",
    "}).reset_index()\n",
    "\n",
    "# ✅ Sort data by annotation_id for clarity\n",
    "segmentedGroundTruth_df = segmentedGroundTruth_df.sort_values(by=[\"annotation_id\", \"frame_start\"])\n",
    "\n",
    "# ✅ Save or display the segmented file\n",
    "segmentedGroundTruth_df.to_csv(\"segmented_midpoint_file.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame              activity  confidence\n",
      "0      1  opening_door_outside       54.08\n",
      "1      2  opening_door_outside       57.44\n",
      "2      3  opening_door_outside       57.44\n",
      "3      4  opening_door_outside       57.44\n",
      "4      5  opening_door_outside       57.44\n",
      "5      6  opening_door_outside       57.44\n",
      "6      7  opening_door_outside       57.44\n",
      "7      8  opening_door_outside       57.44\n",
      "8      9  opening_door_outside       58.80\n",
      "9     10  opening_door_outside       58.80\n"
     ]
    }
   ],
   "source": [
    "# Parse the predictions.log file\n",
    "predictions = []\n",
    "with open('predictions.log', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Split the line to extract frame and activity information\n",
    "            parts = line.strip().split(' - ')  # Splitting by \" - \" to separate timestamp and frame info\n",
    "            frame_part = parts[1].split(': ')[0]  # Extract \"Frame X\"\n",
    "            frame = int(frame_part.split()[1])  # Extract the frame number after \"Frame\"\n",
    "\n",
    "            # Extract activity and confidence\n",
    "            activity_part = parts[1].split(': ', maxsplit=1)[1]  # This contains \"Predicted Activity: XYZ, Confidence: XX.XX%\"\n",
    "            activity = activity_part.split(', Confidence')[0].replace(\"Predicted Activity: \", \"\").strip()  # Extract actual activity\n",
    "            \n",
    "            # Extract confidence if it exists\n",
    "            confidence = 0.0  # Default confidence\n",
    "            if \"Confidence\" in activity_part:  # Check if \"Confidence\" exists in the string\n",
    "                confidence = float(activity_part.split('Confidence: ')[1].strip('%'))  # Extract confidence as float\n",
    "\n",
    "            # Append to predictions list\n",
    "            predictions.append({'frame': frame, 'activity': activity, 'confidence': confidence})\n",
    "        \n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(f\"Skipping line due to error: {line.strip()} -> {e}\")\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Display the predictions DataFrame\n",
    "print(predictions_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define missing frame range (inclusive)\n",
    "missing_intervals = [(266, 2984)]  # Adjust if needed\n",
    "\n",
    "# Function to check if a frame falls within the missing range (inclusive)\n",
    "def is_in_missing_range(frame):\n",
    "    return any(start <= frame <= end for start, end in missing_intervals)\n",
    "\n",
    "# Drop frames within the missing range\n",
    "filtered_predictions_df = predictions_df[~predictions_df['frame'].apply(is_in_missing_range)]\n",
    "filtered_predictions_df.to_csv('filtered_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame_start  frame_end                    activity\n",
      "0           55         90        closing_door_outside\n",
      "1           91        136        opening_door_outside\n",
      "2          137        157                entering_car\n",
      "3          158        184         closing_door_inside\n",
      "4          185        239         fastening_seat_belt\n",
      "5          240       2984    using_multimedia_display\n",
      "6         2985       3007               sitting_still\n",
      "7         3008       3056  pressing_automation_button\n",
      "8         3057       3116               sitting_still\n",
      "9         3117       3154    using_multimedia_display\n"
     ]
    }
   ],
   "source": [
    "#segment the predictions\n",
    "import pandas as pd\n",
    "\n",
    "def convert_predictions_to_segments(predictions):\n",
    "    segments = []\n",
    "    current_activity = None\n",
    "    current_start = None\n",
    "\n",
    "    for idx, row in predictions.iterrows():\n",
    "        frame = row['frame']\n",
    "        activity = row['activity']\n",
    "\n",
    "        # Start a new segment if the activity changes\n",
    "        if activity != current_activity:\n",
    "            if current_activity is not None:\n",
    "                # Save the previous segment\n",
    "                segments.append({\n",
    "                    'frame_start': current_start,\n",
    "                    'frame_end': frame - 1,\n",
    "                    'activity': current_activity\n",
    "                })\n",
    "            # Start a new segment\n",
    "            current_activity = activity\n",
    "            current_start = frame\n",
    "\n",
    "    # Save the last segment\n",
    "    if current_activity is not None:\n",
    "        segments.append({\n",
    "            'frame_start': current_start,\n",
    "            'frame_end': predictions.iloc[-1]['frame'],\n",
    "            'activity': current_activity\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    segments_df = pd.DataFrame(segments)\n",
    "\n",
    "    # Drop the first row\n",
    "    if not segments_df.empty:\n",
    "        segments_df = segments_df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    return segments_df\n",
    "\n",
    "# Example usage\n",
    "segments_df = convert_predictions_to_segments(filtered_predictions_df)\n",
    "\n",
    "# Display the modified segments DataFrame\n",
    "print(segments_df.head(10))\n",
    "segments_df.to_csv('segmented_activities.csv', index=False)\n",
    "\n",
    "# weird segment (240       2984    using_multimedia_display )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['closing_door_outside', 'opening_door_outside', 'entering_car', 'closing_door_inside', 'fastening_seat_belt', 'using_multimedia_display', 'sitting_still', 'pressing_automation_button', 'fetching_an_object', 'opening_laptop', 'working_on_laptop', 'interacting_with_phone', 'closing_laptop', 'placing_an_object', 'unfastening_seat_belt', 'putting_on_jacket', 'opening_bottle', 'drinking', 'closing_bottle', 'looking_or_moving_around (e.g. searching)', 'preparing_food', 'eating', 'taking_off_sunglasses', 'putting_on_sunglasses', 'reading_newspaper', 'writing', 'talking_on_phone', 'reading_magazine', 'taking_off_jacket', 'opening_door_inside', 'exiting_car', 'opening_backpack', 'putting_laptop_into_backpack', 'taking_laptop_from_backpack']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique activities\n",
    "import pandas as pd\n",
    "\n",
    "# Extract the unique activities from the 'activity' column\n",
    "unique_activities = ground_truth['activity'].dropna().unique()\n",
    "\n",
    "# Convert to a list\n",
    "unique_activities_list = list(unique_activities)\n",
    "\n",
    "# Print the unique activities\n",
    "print(unique_activities_list)\n",
    "len(unique_activities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities missing from the dataset: ['opening_backpack', 'putting_laptop_into_backpack', 'taking_laptop_from_backpack']\n"
     ]
    }
   ],
   "source": [
    "# Extract unique activities from the dataset\n",
    "dataset_activities = set(filtered_df['activity'].unique())\n",
    "\n",
    "# Find missing activities\n",
    "missing_activities = [activity for activity in unique_activities_list if activity not in dataset_activities]\n",
    "\n",
    "# Print the missing activities\n",
    "print(\"Activities missing from the dataset:\", missing_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per class (%): {'entering_car': '100.00%', 'looking_or_moving_around (e.g. searching)': '100.00%', 'opening_laptop': '100.00%', 'unfastening_seat_belt': '100.00%', 'talking_on_phone': '100.00%', 'taking_off_sunglasses': '100.00%', 'reading_magazine': '100.00%', 'taking_off_jacket': '100.00%', 'opening_backpack': '0.00%', 'placing_an_object': '100.00%', 'fastening_seat_belt': '100.00%', 'drinking': '100.00%', 'opening_door_outside': '100.00%', 'exiting_car': '100.00%', 'working_on_laptop': '100.00%', 'using_multimedia_display': '100.00%', 'reading_newspaper': '100.00%', 'opening_door_inside': '100.00%', 'sitting_still': '100.00%', 'eating': '100.00%', 'closing_door_outside': '100.00%', 'putting_on_jacket': '100.00%', 'putting_laptop_into_backpack': '0.00%', 'preparing_food': '100.00%', 'pressing_automation_button': '100.00%', 'closing_laptop': '100.00%', 'closing_bottle': '100.00%', 'taking_laptop_from_backpack': '0.00%', 'writing': '100.00%', 'closing_door_inside': '100.00%', 'fetching_an_object': '100.00%', 'interacting_with_phone': '100.00%', 'opening_bottle': '100.00%', 'putting_on_sunglasses': '100.00%'}\n",
      "Recall per class (%): {'entering_car': '100.00%', 'looking_or_moving_around (e.g. searching)': '100.00%', 'opening_laptop': '100.00%', 'unfastening_seat_belt': '60.00%', 'talking_on_phone': '100.00%', 'taking_off_sunglasses': '100.00%', 'reading_magazine': '100.00%', 'taking_off_jacket': '25.00%', 'opening_backpack': '0.00%', 'placing_an_object': '92.31%', 'fastening_seat_belt': '100.00%', 'drinking': '90.00%', 'opening_door_outside': '100.00%', 'exiting_car': '100.00%', 'working_on_laptop': '91.67%', 'using_multimedia_display': '100.00%', 'reading_newspaper': '100.00%', 'opening_door_inside': '100.00%', 'sitting_still': '96.40%', 'eating': '86.67%', 'closing_door_outside': '100.00%', 'putting_on_jacket': '83.33%', 'putting_laptop_into_backpack': '0.00%', 'preparing_food': '100.00%', 'pressing_automation_button': '100.00%', 'closing_laptop': '100.00%', 'closing_bottle': '100.00%', 'taking_laptop_from_backpack': '0.00%', 'writing': '100.00%', 'closing_door_inside': '100.00%', 'fetching_an_object': '29.17%', 'interacting_with_phone': '100.00%', 'opening_bottle': '100.00%', 'putting_on_sunglasses': '66.67%'}\n",
      "Overall Precision: 98.50%\n",
      "Overall Recall: 90.63%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_multiclass(filtered_df, segmented_df, activity_classes):\n",
    "    \"\"\"\n",
    "    Evaluates activity predictions using the Midpoint Hit Criterion.\n",
    "\n",
    "    Fixes:\n",
    "    - Ensures `metrics` includes all activities from `filtered_df` and `segmented_df`.\n",
    "    - Prevents KeyError for missing activities.\n",
    "    - Matches predictions using midpoint hit logic.\n",
    "    - Handles False Positives and False Negatives correctly.\n",
    "\n",
    "    Args:\n",
    "    - filtered_df (pd.DataFrame): Ground truth dataframe with 'frame_start', 'frame_end', 'activity', 'annotation_id', 'chunk_id'.\n",
    "    - segmented_df (pd.DataFrame): Predicted segments dataframe with 'frame_start', 'frame_end', 'activity'.\n",
    "    - activity_classes (list): List of valid activity classes from ground truth.\n",
    "\n",
    "    Returns:\n",
    "    - precision, recall, overall_precision, overall_recall\n",
    "    \"\"\"\n",
    "\n",
    "    #  Fix: Include all activities from both ground truth and predictions\n",
    "    all_activities = set(filtered_df['activity']).union(set(segmented_df['activity']))\n",
    "\n",
    "    # Initialize metrics for all known activities\n",
    "    metrics = {cls: {'tp': 0, 'fp': 0, 'fn': 0} for cls in all_activities}\n",
    "    matched_chunks = set()  # Tracks matched ground truth chunks (annotation_id, chunk_id)\n",
    "\n",
    "    #  Iterate through ground truth activities in `filtered_df`\n",
    "    for _, gt in filtered_df.iterrows():\n",
    "        gt_start = gt['frame_start']\n",
    "        gt_end = gt['frame_end']\n",
    "        gt_activity = gt['activity']\n",
    "        chunk_key = (gt['annotation_id'], gt['chunk_id'])\n",
    "\n",
    "        #  Compute the exact midpoint of the ground truth segment\n",
    "        gt_midpoint = (gt_start + gt_end) // 2\n",
    "\n",
    "        #  Find prediction that matches the midpoint\n",
    "        matched_prediction = segmented_df[\n",
    "            (segmented_df['frame_start'] <= gt_midpoint) &\n",
    "            (segmented_df['frame_end'] >= gt_midpoint) &\n",
    "            (segmented_df['activity'] == gt_activity)\n",
    "        ]\n",
    "\n",
    "        if not matched_prediction.empty:\n",
    "            #  True Positive: A prediction exists for this midpoint\n",
    "            if chunk_key not in matched_chunks:\n",
    "                metrics[gt_activity]['tp'] += 1  # Count as TP\n",
    "                matched_chunks.add(chunk_key)  # Prevent duplicate matches\n",
    "            else:\n",
    "                metrics[gt_activity]['fp'] += 1  # False Positive for duplicates\n",
    "        else:\n",
    "            # False Negative: No correct prediction found for this activity midpoint\n",
    "            metrics[gt_activity]['fn'] += 1\n",
    "\n",
    "    # Count False Positives for unmatched predictions\n",
    "    for _, pred in segmented_df.iterrows():\n",
    "        pred_activity = pred['activity']\n",
    "\n",
    "        #  Ignore if the activity was already correctly matched\n",
    "        if pred_activity in metrics and metrics[pred_activity]['tp'] > 0:\n",
    "            continue\n",
    "\n",
    "        #  Fix: Ensure `pred_activity` exists in `metrics` before updating\n",
    "        if pred_activity not in metrics:\n",
    "            continue  # Ignore activities that are not in ground truth\n",
    "\n",
    "        #  False Positive: No corresponding ground truth found for this prediction\n",
    "        metrics[pred_activity]['fp'] += 1\n",
    "\n",
    "    #  Compute Precision & Recall for each activity\n",
    "    precision, recall = {}, {}\n",
    "    for cls in all_activities:\n",
    "        tp, fp, fn = metrics[cls]['tp'], metrics[cls]['fp'], metrics[cls]['fn']\n",
    "        precision[cls] = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0\n",
    "        recall[cls] = tp / (tp + fn) * 100 if (tp + fn) > 0 else 0\n",
    "\n",
    "    #  Compute Overall Precision & Recall\n",
    "    overall_tp = sum(metrics[cls]['tp'] for cls in all_activities)\n",
    "    overall_fp = sum(metrics[cls]['fp'] for cls in all_activities)\n",
    "    overall_fn = sum(metrics[cls]['fn'] for cls in all_activities)\n",
    "\n",
    "    overall_precision = overall_tp / (overall_tp + overall_fp) * 100 if (overall_tp + overall_fp) > 0 else 0\n",
    "    overall_recall = overall_tp / (overall_tp + overall_fn) * 100 if (overall_tp + overall_fn) > 0 else 0\n",
    "\n",
    "    return precision, recall, overall_precision, overall_recall\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "dataset_activities = set(filtered_df['activity'].unique())\n",
    "\n",
    "# Remove missing activities from evaluation (Only keep ones that exist in ground truth)\n",
    "filtered_activity_classes = [activity for activity in unique_activities_list if activity in dataset_activities]\n",
    "\n",
    "# Run the evaluation\n",
    "precision, recall, overall_precision, overall_recall = evaluate_multiclass(filtered_df, segments_df, filtered_activity_classes)\n",
    "\n",
    "#  Print results\n",
    "print(\"Precision per class (%):\", {cls: f\"{precision[cls]:.2f}%\" for cls in precision})\n",
    "print(\"Recall per class (%):\", {cls: f\"{recall[cls]:.2f}%\" for cls in recall})\n",
    "print(f\"Overall Precision: {overall_precision:.2f}%\")\n",
    "print(f\"Overall Recall: {overall_recall:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
